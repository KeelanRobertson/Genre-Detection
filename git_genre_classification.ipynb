{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import scipy.stats.stats as stats\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if a gpu is available\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('track_features_final.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = pd.read_csv('meta_final.csv', index_col = 0)\n",
    "meta.rename(columns={'Track ID': 'track_id'}, inplace=True)\n",
    "tracks = df.merge(meta, on='track_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>track_id</th>\n",
       "      <th>title</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>acousticness</th>\n",
       "      <th>danceability</th>\n",
       "      <th>energy</th>\n",
       "      <th>instrumentalness</th>\n",
       "      <th>liveness</th>\n",
       "      <th>speechiness</th>\n",
       "      <th>...</th>\n",
       "      <th>mfccs_mean15</th>\n",
       "      <th>mfccs_var15</th>\n",
       "      <th>mfccs_mean16</th>\n",
       "      <th>mfccs_var16</th>\n",
       "      <th>mfccs_mean17</th>\n",
       "      <th>mfccs_var17</th>\n",
       "      <th>mfccs_mean18</th>\n",
       "      <th>mfccs_var18</th>\n",
       "      <th>mfccs_mean19</th>\n",
       "      <th>mfccs_var19</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>Food</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>0.416675</td>\n",
       "      <td>0.675894</td>\n",
       "      <td>0.634476</td>\n",
       "      <td>0.010628</td>\n",
       "      <td>0.177647</td>\n",
       "      <td>0.159310</td>\n",
       "      <td>...</td>\n",
       "      <td>1.253358</td>\n",
       "      <td>49.994880</td>\n",
       "      <td>-8.481487</td>\n",
       "      <td>53.345783</td>\n",
       "      <td>-2.040749</td>\n",
       "      <td>52.196274</td>\n",
       "      <td>-2.946624</td>\n",
       "      <td>51.77792</td>\n",
       "      <td>0.094077</td>\n",
       "      <td>40.441700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5</td>\n",
       "      <td>This World</td>\n",
       "      <td>AWOL</td>\n",
       "      <td>Hip-Hop</td>\n",
       "      <td>0.043567</td>\n",
       "      <td>0.745566</td>\n",
       "      <td>0.701470</td>\n",
       "      <td>0.000697</td>\n",
       "      <td>0.373143</td>\n",
       "      <td>0.124595</td>\n",
       "      <td>...</td>\n",
       "      <td>0.919858</td>\n",
       "      <td>66.263405</td>\n",
       "      <td>-4.126342</td>\n",
       "      <td>44.906055</td>\n",
       "      <td>-0.580666</td>\n",
       "      <td>44.026913</td>\n",
       "      <td>-1.600445</td>\n",
       "      <td>65.26340</td>\n",
       "      <td>1.350323</td>\n",
       "      <td>64.534930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10</td>\n",
       "      <td>Freeway</td>\n",
       "      <td>Kurt Vile</td>\n",
       "      <td>Pop</td>\n",
       "      <td>0.951670</td>\n",
       "      <td>0.658179</td>\n",
       "      <td>0.924525</td>\n",
       "      <td>0.965427</td>\n",
       "      <td>0.115474</td>\n",
       "      <td>0.032985</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.911099</td>\n",
       "      <td>42.735588</td>\n",
       "      <td>-3.207996</td>\n",
       "      <td>32.780640</td>\n",
       "      <td>3.043154</td>\n",
       "      <td>40.873420</td>\n",
       "      <td>-1.036512</td>\n",
       "      <td>30.22485</td>\n",
       "      <td>3.882601</td>\n",
       "      <td>29.444992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140</td>\n",
       "      <td>Queen Of The Wires</td>\n",
       "      <td>Alec K. Redfearn &amp; the Eyesores</td>\n",
       "      <td>Folk</td>\n",
       "      <td>0.376312</td>\n",
       "      <td>0.734079</td>\n",
       "      <td>0.265685</td>\n",
       "      <td>0.669581</td>\n",
       "      <td>0.085995</td>\n",
       "      <td>0.039068</td>\n",
       "      <td>...</td>\n",
       "      <td>1.239001</td>\n",
       "      <td>43.232227</td>\n",
       "      <td>-5.205992</td>\n",
       "      <td>38.285038</td>\n",
       "      <td>-0.754437</td>\n",
       "      <td>39.603607</td>\n",
       "      <td>-6.319377</td>\n",
       "      <td>47.34824</td>\n",
       "      <td>-1.172379</td>\n",
       "      <td>44.371730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>141</td>\n",
       "      <td>Ohio</td>\n",
       "      <td>Alec K. Redfearn &amp; the Eyesores</td>\n",
       "      <td>Folk</td>\n",
       "      <td>0.963657</td>\n",
       "      <td>0.435933</td>\n",
       "      <td>0.075632</td>\n",
       "      <td>0.345493</td>\n",
       "      <td>0.105686</td>\n",
       "      <td>0.026658</td>\n",
       "      <td>...</td>\n",
       "      <td>5.053833</td>\n",
       "      <td>99.240820</td>\n",
       "      <td>-0.170090</td>\n",
       "      <td>91.179344</td>\n",
       "      <td>3.087437</td>\n",
       "      <td>62.452350</td>\n",
       "      <td>-8.665928</td>\n",
       "      <td>70.66697</td>\n",
       "      <td>-1.098168</td>\n",
       "      <td>89.260025</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 87 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   track_id               title                           artist    genre  \\\n",
       "0         2                Food                             AWOL  Hip-Hop   \n",
       "1         5          This World                             AWOL  Hip-Hop   \n",
       "2        10             Freeway                        Kurt Vile      Pop   \n",
       "3       140  Queen Of The Wires  Alec K. Redfearn & the Eyesores     Folk   \n",
       "4       141                Ohio  Alec K. Redfearn & the Eyesores     Folk   \n",
       "\n",
       "   acousticness  danceability    energy  instrumentalness  liveness  \\\n",
       "0      0.416675      0.675894  0.634476          0.010628  0.177647   \n",
       "1      0.043567      0.745566  0.701470          0.000697  0.373143   \n",
       "2      0.951670      0.658179  0.924525          0.965427  0.115474   \n",
       "3      0.376312      0.734079  0.265685          0.669581  0.085995   \n",
       "4      0.963657      0.435933  0.075632          0.345493  0.105686   \n",
       "\n",
       "   speechiness  ...  mfccs_mean15  mfccs_var15  mfccs_mean16  mfccs_var16  \\\n",
       "0     0.159310  ...      1.253358    49.994880     -8.481487    53.345783   \n",
       "1     0.124595  ...      0.919858    66.263405     -4.126342    44.906055   \n",
       "2     0.032985  ...     -0.911099    42.735588     -3.207996    32.780640   \n",
       "3     0.039068  ...      1.239001    43.232227     -5.205992    38.285038   \n",
       "4     0.026658  ...      5.053833    99.240820     -0.170090    91.179344   \n",
       "\n",
       "   mfccs_mean17  mfccs_var17  mfccs_mean18  mfccs_var18  mfccs_mean19  \\\n",
       "0     -2.040749    52.196274     -2.946624     51.77792      0.094077   \n",
       "1     -0.580666    44.026913     -1.600445     65.26340      1.350323   \n",
       "2      3.043154    40.873420     -1.036512     30.22485      3.882601   \n",
       "3     -0.754437    39.603607     -6.319377     47.34824     -1.172379   \n",
       "4      3.087437    62.452350     -8.665928     70.66697     -1.098168   \n",
       "\n",
       "   mfccs_var19  \n",
       "0    40.441700  \n",
       "1    64.534930  \n",
       "2    29.444992  \n",
       "3    44.371730  \n",
       "4    89.260025  \n",
       "\n",
       "[5 rows x 87 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tracks.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['zero_crossings', 'tempo_y', 'spec_cent_mean',\n",
    "       'spec_cent_var', 'spectral_rolloff_mean', 'spectral_rolloff_var',\n",
    "       'chroma_mean0', 'chroma_var0', 'chroma_mean1', 'chroma_var1',\n",
    "       'chroma_mean2', 'chroma_var2', 'chroma_mean3', 'chroma_var3',\n",
    "       'chroma_mean4', 'chroma_var4', 'chroma_mean5', 'chroma_var5',\n",
    "       'chroma_mean6', 'chroma_var6', 'chroma_mean7', 'chroma_var7',\n",
    "       'chroma_mean8', 'chroma_var8', 'chroma_mean9', 'chroma_var9',\n",
    "       'chroma_mean10', 'chroma_var10', 'chroma_mean11', 'chroma_var11',\n",
    "       'harm_mean', 'perc_mean', 'harm_var', 'perc_var', 'mfccs_mean0',\n",
    "       'mfccs_var0', 'mfccs_mean1', 'mfccs_var1', 'mfccs_mean2', 'mfccs_var2',\n",
    "       'mfccs_mean3', 'mfccs_var3', 'mfccs_mean4', 'mfccs_var4', 'mfccs_mean5',\n",
    "       'mfccs_var5', 'mfccs_mean6', 'mfccs_var6', 'mfccs_mean7', 'mfccs_var7',\n",
    "       'mfccs_mean8', 'mfccs_var8', 'mfccs_mean9', 'mfccs_var9',\n",
    "       'mfccs_mean10', 'mfccs_var10', 'mfccs_mean11', 'mfccs_var11',\n",
    "       'mfccs_mean12', 'mfccs_var12', 'mfccs_mean13', 'mfccs_var13',\n",
    "       'mfccs_mean14', 'mfccs_var14', 'mfccs_mean15', 'mfccs_var15',\n",
    "       'mfccs_mean16', 'mfccs_var16', 'mfccs_mean17', 'mfccs_var17',\n",
    "       'mfccs_mean18', 'mfccs_var18', 'mfccs_mean19', 'mfccs_var19']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Folk             587\n",
       "Rock             535\n",
       "Instrumental     456\n",
       "Pop              445\n",
       "Hip-Hop          406\n",
       "Electronic       380\n",
       "International    301\n",
       "Experimental     171\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tracks.genre.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of features with a low VIF\n",
    "feat_cols= ['spectral_rolloff_mean',\n",
    "     'mfccs_mean7',\n",
    "     'mfccs_mean8',\n",
    "     'mfccs_mean9',\n",
    "     'chroma_mean1',\n",
    "     'chroma_mean4',\n",
    "     'chroma_mean10',\n",
    "     'mfccs_mean10',\n",
    "     'mfccs_mean4',\n",
    "     'mfccs_mean0',\n",
    "     'spec_cent_var',\n",
    "     'mfccs_var7',\n",
    "     'mfccs_var18',\n",
    "     'zero_crossings',\n",
    "     'mfccs_mean2',\n",
    "     'mfccs_mean1',\n",
    "     'mfccs_var6']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([469, 469, 469, 469, 469, 469, 469, 469], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# oversample the data and split it into train and test\n",
    "X = tracks[feat_cols]\n",
    "y = tracks['genre']\n",
    " \n",
    "converter = LabelEncoder()\n",
    "converter.fit(y)\n",
    "y = converter.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sample = SMOTE()\n",
    "X_train, y_train = sample.fit_resample(X_train, y_train)\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {'C' : np.logspace(-4, 4, 20),\n",
    "              'solver' : ['newton-cg', 'lbfgs'],}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = GridSearchCV(estimator = LogisticRegression(), param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 40 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vijal\\.conda\\envs\\gputest\\lib\\site-packages\\scipy\\optimize\\linesearch.py:466: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\vijal\\.conda\\envs\\gputest\\lib\\site-packages\\scipy\\optimize\\linesearch.py:314: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "C:\\Users\\vijal\\.conda\\envs\\gputest\\lib\\site-packages\\sklearn\\utils\\optimize.py:203: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  \"number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(), n_jobs=-1,\n",
       "             param_grid={'C': array([1.00000000e-04, 2.63665090e-04, 6.95192796e-04, 1.83298071e-03,\n",
       "       4.83293024e-03, 1.27427499e-02, 3.35981829e-02, 8.85866790e-02,\n",
       "       2.33572147e-01, 6.15848211e-01, 1.62377674e+00, 4.28133240e+00,\n",
       "       1.12883789e+01, 2.97635144e+01, 7.84759970e+01, 2.06913808e+02,\n",
       "       5.45559478e+02, 1.43844989e+03, 3.79269019e+03, 1.00000000e+04]),\n",
       "                         'solver': ['newton-cg', 'lbfgs']},\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'C': 78.47599703514607, 'solver': 'newton-cg'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_train = lr.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.32      0.34      0.33       469\n",
      "           1       0.26      0.11      0.15       469\n",
      "           2       0.46      0.46      0.46       469\n",
      "           3       0.52      0.59      0.55       469\n",
      "           4       0.49      0.61      0.54       469\n",
      "           5       0.41      0.41      0.41       469\n",
      "           6       0.33      0.21      0.26       469\n",
      "           7       0.46      0.68      0.55       469\n",
      "\n",
      "    accuracy                           0.43      3752\n",
      "   macro avg       0.41      0.43      0.41      3752\n",
      "weighted avg       0.41      0.43      0.41      3752\n",
      "\n",
      "[[161  19  15 115  70  32  12  45]\n",
      " [ 58  51  61  25  80  69  33  92]\n",
      " [ 18  23 218   9  80  43  45  33]\n",
      " [ 74  22  11 277   9  15  24  37]\n",
      " [ 36  14  55   7 288  27   6  36]\n",
      " [ 53  35  42  44  28 192  50  25]\n",
      " [ 76  20  57  38  16  62  98 102]\n",
      " [ 25  13  20  22  20  23  27 319]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, lr_pred_train))\n",
    "print(metrics.confusion_matrix(y_train, lr_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_pred_test = lr.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.38      0.47      0.42        75\n",
      "           1       0.06      0.07      0.07        29\n",
      "           2       0.59      0.48      0.53       118\n",
      "           3       0.46      0.51      0.48        87\n",
      "           4       0.51      0.51      0.51        81\n",
      "           5       0.32      0.40      0.35        65\n",
      "           6       0.33      0.17      0.23        87\n",
      "           7       0.57      0.65      0.61       115\n",
      "\n",
      "    accuracy                           0.45       657\n",
      "   macro avg       0.40      0.41      0.40       657\n",
      "weighted avg       0.45      0.45      0.44       657\n",
      "\n",
      "[[35  0  3 18  4  4  4  7]\n",
      " [ 2  2  7  2  5  4  2  5]\n",
      " [ 6  5 57  3 18 14  8  7]\n",
      " [19  7  1 44  1  4  5  6]\n",
      " [ 3  3  8  6 41  8  4  8]\n",
      " [11  5  3  8  2 26  6  4]\n",
      " [10  3 12  9  5 13 15 20]\n",
      " [ 7  6  6  6  4  9  2 75]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, lr_pred_test))\n",
    "print(metrics.confusion_matrix(y_test, lr_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([469, 469, 469, 469, 469, 469, 469, 469], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# oversample the data and split it into train and test\n",
    "X = tracks[cols]\n",
    "y = tracks['genre']\n",
    " \n",
    "converter = LabelEncoder()\n",
    "converter.fit(y)\n",
    "y = converter.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sample = SMOTE()\n",
    "X_train, y_train = sample.fit_resample(X_train, y_train)\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale the train and test sets using the min-max scaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate the error for 40 iterations of KNN\n",
    "errors = []\n",
    "\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    errors.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the error against the k-value\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40)\n",
    "         , errors\n",
    "         , color='black'\n",
    "         , linestyle='dashed'\n",
    "         , marker='o'\n",
    "         , markerfacecolor='grey'\n",
    "         , markersize=10)\n",
    "plt.title('Error Rate K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('Mean Error')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier(n_neighbors=10)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier = KNeighborsClassifier(n_neighbors=10)\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred_train = classifier.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.70      0.63      0.66       469\n",
      "           1       0.67      0.86      0.75       469\n",
      "           2       0.71      0.54      0.61       469\n",
      "           3       0.61      0.81      0.70       469\n",
      "           4       0.81      0.58      0.68       469\n",
      "           5       0.55      0.78      0.64       469\n",
      "           6       0.55      0.45      0.49       469\n",
      "           7       0.75      0.58      0.66       469\n",
      "\n",
      "    accuracy                           0.65      3752\n",
      "   macro avg       0.67      0.65      0.65      3752\n",
      "weighted avg       0.67      0.65      0.65      3752\n",
      "\n",
      "[[295  21  10  70  13  32  20   8]\n",
      " [  8 403   4  15   2  17   8  12]\n",
      " [  9  38 254   7  26  73  46  16]\n",
      " [ 44   5   1 381   3  20  10   5]\n",
      " [ 15  48  44  24 273  34  19  12]\n",
      " [  9  17   5  47   3 364  18   6]\n",
      " [ 20  38  29  54   7  81 209  31]\n",
      " [ 22  35  11  26   9  46  47 273]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, knn_pred_train))\n",
    "print(confusion_matrix(y_train, knn_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_pred_test = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.35      0.32      0.34        75\n",
      "           1       0.14      0.28      0.18        29\n",
      "           2       0.59      0.46      0.51       118\n",
      "           3       0.57      0.71      0.63        87\n",
      "           4       0.63      0.38      0.48        81\n",
      "           5       0.30      0.60      0.40        65\n",
      "           6       0.28      0.22      0.24        87\n",
      "           7       0.65      0.44      0.53       115\n",
      "\n",
      "    accuracy                           0.44       657\n",
      "   macro avg       0.44      0.43      0.41       657\n",
      "weighted avg       0.48      0.44      0.44       657\n",
      "\n",
      "[[24  3  5 19  2  7  8  7]\n",
      " [ 3  8  3  1  1  7  3  3]\n",
      " [ 1 12 54  2  7 29 12  1]\n",
      " [13  1  0 62  0  6  3  2]\n",
      " [ 6  3 16  3 31 11  7  4]\n",
      " [ 5  8  3  5  1 39  2  2]\n",
      " [ 7 11  7 12  5 17 19  9]\n",
      " [ 9 13  4  5  2 16 15 51]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, knn_pred_test))\n",
    "print(confusion_matrix(y_test, knn_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([469, 469, 469, 469, 469, 469, 469, 469], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# oversample the data and split it into train and test\n",
    "X = tracks[cols]\n",
    "y = tracks['genre']\n",
    " \n",
    "converter = LabelEncoder()\n",
    "converter.fit(y)\n",
    "y = converter.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "sample = SMOTE()\n",
    "X_train, y_train = sample.fit_resample(X_train, y_train)\n",
    "print(np.unique(y_train, return_counts=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [200,400,600],\n",
    "    'max_depth': [2,4,6,8],\n",
    "    'max_features' : [15,25,35],\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 27 candidates, totalling 135 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 100, 'max_features': 40, 'n_estimators': 300}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [100, 200, 300],\n",
    "    'max_features' : [40, 50 , 60],\n",
    "    \n",
    "}\n",
    "\n",
    "rf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=rf_params, cv=5, verbose=3, n_jobs=-2)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.38      0.36       469\n",
      "           1       0.23      0.11      0.15       469\n",
      "           2       0.46      0.46      0.46       469\n",
      "           3       0.50      0.59      0.54       469\n",
      "           4       0.49      0.60      0.54       469\n",
      "           5       0.43      0.43      0.43       469\n",
      "           6       0.33      0.19      0.24       469\n",
      "           7       0.46      0.69      0.55       469\n",
      "\n",
      "    accuracy                           0.43      3752\n",
      "   macro avg       0.41      0.43      0.41      3752\n",
      "weighted avg       0.41      0.43      0.41      3752\n",
      "\n",
      "[[177  23  12 110  62  31  17  37]\n",
      " [ 66  50  67  25  65  63  27 106]\n",
      " [ 19  27 218   8  79  43  39  36]\n",
      " [ 78  23  12 276  11  15  22  32]\n",
      " [ 38  18  56  11 280  24   7  35]\n",
      " [ 46  41  32  54  30 200  40  26]\n",
      " [ 70  22  57  45  21  64  88 102]\n",
      " [ 25  12  19  22  22  22  25 322]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, lr_pred_train))\n",
    "print(metrics.confusion_matrix(y_train, lr_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_test = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.44      0.46        75\n",
      "           1       0.30      0.24      0.27        29\n",
      "           2       0.62      0.69      0.66       118\n",
      "           3       0.66      0.75      0.70        87\n",
      "           4       0.63      0.51      0.56        81\n",
      "           5       0.47      0.55      0.51        65\n",
      "           6       0.35      0.33      0.34        87\n",
      "           7       0.66      0.63      0.64       115\n",
      "\n",
      "    accuracy                           0.56       657\n",
      "   macro avg       0.52      0.52      0.52       657\n",
      "weighted avg       0.55      0.56      0.55       657\n",
      "\n",
      "[[33  2  1 13  5  4  9  8]\n",
      " [ 2  7  4  1  4  3  3  5]\n",
      " [ 1  1 82  2 10  8 14  0]\n",
      " [13  0  0 65  1  4  2  2]\n",
      " [ 5  3 14  1 41  7  5  5]\n",
      " [ 4  0  5  7  1 36 10  2]\n",
      " [ 7  5 17  5  2  7 29 15]\n",
      " [ 5  5  9  4  1  8 11 72]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, rf_pred_test))\n",
    "print(metrics.confusion_matrix(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 84 candidates, totalling 420 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 150, 'max_features': 25, 'n_estimators': 400}"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_params = {\n",
    "    'n_estimators': [200,400,600],\n",
    "    'max_depth': [2,4,6,8,50,100,150],\n",
    "    'max_features' : [15,25,35,45],\n",
    "    \n",
    "}\n",
    "rf = GridSearchCV(estimator=RandomForestClassifier(), param_grid=rf_params, cv=5, verbose=3, n_jobs=-2)\n",
    "\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "rf.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_train = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.34      0.38      0.36       469\n",
      "           1       0.23      0.11      0.15       469\n",
      "           2       0.46      0.46      0.46       469\n",
      "           3       0.50      0.59      0.54       469\n",
      "           4       0.49      0.60      0.54       469\n",
      "           5       0.43      0.43      0.43       469\n",
      "           6       0.33      0.19      0.24       469\n",
      "           7       0.46      0.69      0.55       469\n",
      "\n",
      "    accuracy                           0.43      3752\n",
      "   macro avg       0.41      0.43      0.41      3752\n",
      "weighted avg       0.41      0.43      0.41      3752\n",
      "\n",
      "[[177  23  12 110  62  31  17  37]\n",
      " [ 66  50  67  25  65  63  27 106]\n",
      " [ 19  27 218   8  79  43  39  36]\n",
      " [ 78  23  12 276  11  15  22  32]\n",
      " [ 38  18  56  11 280  24   7  35]\n",
      " [ 46  41  32  54  30 200  40  26]\n",
      " [ 70  22  57  45  21  64  88 102]\n",
      " [ 25  12  19  22  22  22  25 322]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, lr_pred_train))\n",
    "print(metrics.confusion_matrix(y_train, lr_pred_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_pred_test = rf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Electronic       0.44      0.41      0.43        75\n",
      " Experimental       0.39      0.31      0.35        29\n",
      "         Folk       0.64      0.69      0.67       118\n",
      "      Hip-Hop       0.64      0.72      0.68        87\n",
      " Instrumental       0.60      0.51      0.55        81\n",
      "International       0.49      0.55      0.52        65\n",
      "          Pop       0.41      0.38      0.39        87\n",
      "         Rock       0.65      0.65      0.65       115\n",
      "\n",
      "     accuracy                           0.56       657\n",
      "    macro avg       0.53      0.53      0.53       657\n",
      " weighted avg       0.56      0.56      0.56       657\n",
      "\n",
      "[[31  2  2 16  5  2  9  8]\n",
      " [ 1  9  4  1  6  2  3  3]\n",
      " [ 1  0 82  2 10 10 12  1]\n",
      " [15  1  1 63  1  3  1  2]\n",
      " [ 5  4 12  1 41  7  6  5]\n",
      " [ 6  0  3  6  1 36  9  4]\n",
      " [ 4  3 16  6  2  6 33 17]\n",
      " [ 7  4  8  3  2  8  8 75]]\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(converter.inverse_transform(y_test), converter.inverse_transform(rf_pred_test)))\n",
    "print(metrics.confusion_matrix(y_test, rf_pred_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([0, 1, 2, 3, 4, 5, 6, 7]), array([469, 469, 469, 469, 469, 469, 469, 469], dtype=int64))\n"
     ]
    }
   ],
   "source": [
    "# oversample the data and split it into train and test\n",
    "X = tracks[cols]\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X)\n",
    "X = scaler.transform(X)\n",
    "y = tracks['genre']\n",
    " \n",
    "converter = LabelEncoder()\n",
    "converter.fit(y)\n",
    "y = converter.transform(y)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "sample = SMOTE()\n",
    "X_train, y_train = sample.fit_resample(X_train, y_train)\n",
    "print(np.unique(y_train, return_counts=True))\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear any previous tensorflow sessions\n",
    "tf.keras.backend.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 512)               38400     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 8)                 520       \n",
      "=================================================================\n",
      "Total params: 211,400\n",
      "Trainable params: 211,400\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    tf.keras.layers.Dense(512, activation='relu', input_shape=(X_train.shape[1],)), #kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.05, seed=None)),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(256, activation='relu'),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    #tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "#     tf.keras.layers.Dense(32, activation='relu'),\n",
    "#     #tf.keras.layers.BatchNormalization(),\n",
    "#     tf.keras.layers.Dropout(0.2),\n",
    "    \n",
    "    tf.keras.layers.Dense(8, activation='softmax'),\n",
    "])\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a callback to prevent overfitting\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.00002)\n",
    "loss = tf.keras.losses.CategoricalCrossentropy()\n",
    "model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/600\n",
      "15/15 [==============================] - 0s 16ms/step - loss: 2.1116 - accuracy: 0.1189 - val_loss: 2.0752 - val_accuracy: 0.1202\n",
      "Epoch 2/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0974 - accuracy: 0.1282 - val_loss: 2.0628 - val_accuracy: 0.1507\n",
      "Epoch 3/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0862 - accuracy: 0.1410 - val_loss: 2.0511 - val_accuracy: 0.1796\n",
      "Epoch 4/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0722 - accuracy: 0.1503 - val_loss: 2.0405 - val_accuracy: 0.2085\n",
      "Epoch 5/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.0526 - accuracy: 0.1631 - val_loss: 2.0298 - val_accuracy: 0.2374\n",
      "Epoch 6/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.0450 - accuracy: 0.1714 - val_loss: 2.0193 - val_accuracy: 0.2481\n",
      "Epoch 7/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0350 - accuracy: 0.1839 - val_loss: 2.0080 - val_accuracy: 0.2755\n",
      "Epoch 8/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.0242 - accuracy: 0.1914 - val_loss: 1.9962 - val_accuracy: 0.2907\n",
      "Epoch 9/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 2.0167 - accuracy: 0.2055 - val_loss: 1.9849 - val_accuracy: 0.3075\n",
      "Epoch 10/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 2.0040 - accuracy: 0.2188 - val_loss: 1.9724 - val_accuracy: 0.3227\n",
      "Epoch 11/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.9961 - accuracy: 0.2244 - val_loss: 1.9593 - val_accuracy: 0.3394\n",
      "Epoch 12/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9849 - accuracy: 0.2348 - val_loss: 1.9462 - val_accuracy: 0.3592\n",
      "Epoch 13/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9710 - accuracy: 0.2409 - val_loss: 1.9318 - val_accuracy: 0.3790\n",
      "Epoch 14/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9603 - accuracy: 0.2583 - val_loss: 1.9168 - val_accuracy: 0.3836\n",
      "Epoch 15/600\n",
      "15/15 [==============================] - 0s 6ms/step - loss: 1.9430 - accuracy: 0.2732 - val_loss: 1.9016 - val_accuracy: 0.4003\n",
      "Epoch 16/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.9353 - accuracy: 0.2788 - val_loss: 1.8859 - val_accuracy: 0.4049\n",
      "Epoch 17/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.9201 - accuracy: 0.2799 - val_loss: 1.8694 - val_accuracy: 0.4064\n",
      "Epoch 18/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.9060 - accuracy: 0.3012 - val_loss: 1.8536 - val_accuracy: 0.4094\n",
      "Epoch 19/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.8902 - accuracy: 0.3054 - val_loss: 1.8381 - val_accuracy: 0.4125\n",
      "Epoch 20/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8826 - accuracy: 0.3076 - val_loss: 1.8224 - val_accuracy: 0.4155\n",
      "Epoch 21/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8659 - accuracy: 0.3166 - val_loss: 1.8076 - val_accuracy: 0.4186\n",
      "Epoch 22/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.8492 - accuracy: 0.3230 - val_loss: 1.7924 - val_accuracy: 0.4231\n",
      "Epoch 23/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.8472 - accuracy: 0.3188 - val_loss: 1.7787 - val_accuracy: 0.4231\n",
      "Epoch 24/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.8324 - accuracy: 0.3318 - val_loss: 1.7643 - val_accuracy: 0.4231\n",
      "Epoch 25/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.8167 - accuracy: 0.3361 - val_loss: 1.7508 - val_accuracy: 0.4201\n",
      "Epoch 26/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.8000 - accuracy: 0.3489 - val_loss: 1.7384 - val_accuracy: 0.4201\n",
      "Epoch 27/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7868 - accuracy: 0.3494 - val_loss: 1.7265 - val_accuracy: 0.4201\n",
      "Epoch 28/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.7829 - accuracy: 0.3404 - val_loss: 1.7146 - val_accuracy: 0.4201\n",
      "Epoch 29/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.7662 - accuracy: 0.3643 - val_loss: 1.7039 - val_accuracy: 0.4262\n",
      "Epoch 30/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7727 - accuracy: 0.3481 - val_loss: 1.6934 - val_accuracy: 0.4338\n",
      "Epoch 31/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7524 - accuracy: 0.3630 - val_loss: 1.6835 - val_accuracy: 0.4338\n",
      "Epoch 32/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.7464 - accuracy: 0.3643 - val_loss: 1.6744 - val_accuracy: 0.4323\n",
      "Epoch 33/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.7381 - accuracy: 0.3598 - val_loss: 1.6658 - val_accuracy: 0.4368\n",
      "Epoch 34/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7179 - accuracy: 0.3718 - val_loss: 1.6572 - val_accuracy: 0.4384\n",
      "Epoch 35/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7195 - accuracy: 0.3654 - val_loss: 1.6490 - val_accuracy: 0.4444\n",
      "Epoch 36/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.6991 - accuracy: 0.3718 - val_loss: 1.6413 - val_accuracy: 0.4475\n",
      "Epoch 37/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.7043 - accuracy: 0.3713 - val_loss: 1.6335 - val_accuracy: 0.4490\n",
      "Epoch 38/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.7035 - accuracy: 0.3774 - val_loss: 1.6275 - val_accuracy: 0.4536\n",
      "Epoch 39/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.7070 - accuracy: 0.3707 - val_loss: 1.6217 - val_accuracy: 0.4536\n",
      "Epoch 40/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6870 - accuracy: 0.3862 - val_loss: 1.6161 - val_accuracy: 0.4566\n",
      "Epoch 41/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6774 - accuracy: 0.3777 - val_loss: 1.6096 - val_accuracy: 0.4566\n",
      "Epoch 42/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6670 - accuracy: 0.3830 - val_loss: 1.6037 - val_accuracy: 0.4597\n",
      "Epoch 43/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6614 - accuracy: 0.3867 - val_loss: 1.5979 - val_accuracy: 0.4597\n",
      "Epoch 44/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.6519 - accuracy: 0.3931 - val_loss: 1.5914 - val_accuracy: 0.4703\n",
      "Epoch 45/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6514 - accuracy: 0.3915 - val_loss: 1.5864 - val_accuracy: 0.4673\n",
      "Epoch 46/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6443 - accuracy: 0.3987 - val_loss: 1.5815 - val_accuracy: 0.4673\n",
      "Epoch 47/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.6433 - accuracy: 0.4006 - val_loss: 1.5774 - val_accuracy: 0.4658\n",
      "Epoch 48/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.6281 - accuracy: 0.4096 - val_loss: 1.5722 - val_accuracy: 0.4764\n",
      "Epoch 49/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.6071 - accuracy: 0.4096 - val_loss: 1.5673 - val_accuracy: 0.4764\n",
      "Epoch 50/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6074 - accuracy: 0.4128 - val_loss: 1.5623 - val_accuracy: 0.4795\n",
      "Epoch 51/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6223 - accuracy: 0.4046 - val_loss: 1.5588 - val_accuracy: 0.4795\n",
      "Epoch 52/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6155 - accuracy: 0.4054 - val_loss: 1.5556 - val_accuracy: 0.4840\n",
      "Epoch 53/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.6032 - accuracy: 0.4062 - val_loss: 1.5508 - val_accuracy: 0.4810\n",
      "Epoch 54/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5948 - accuracy: 0.4182 - val_loss: 1.5468 - val_accuracy: 0.4810\n",
      "Epoch 55/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5869 - accuracy: 0.4216 - val_loss: 1.5437 - val_accuracy: 0.4810\n",
      "Epoch 56/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5853 - accuracy: 0.4174 - val_loss: 1.5404 - val_accuracy: 0.4840\n",
      "Epoch 57/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5855 - accuracy: 0.4198 - val_loss: 1.5369 - val_accuracy: 0.4855\n",
      "Epoch 58/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.5677 - accuracy: 0.4312 - val_loss: 1.5332 - val_accuracy: 0.4871\n",
      "Epoch 59/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.5661 - accuracy: 0.4278 - val_loss: 1.5301 - val_accuracy: 0.4855\n",
      "Epoch 60/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5615 - accuracy: 0.4419 - val_loss: 1.5270 - val_accuracy: 0.4840\n",
      "Epoch 61/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5540 - accuracy: 0.4371 - val_loss: 1.5234 - val_accuracy: 0.4855\n",
      "Epoch 62/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5574 - accuracy: 0.4344 - val_loss: 1.5198 - val_accuracy: 0.4901\n",
      "Epoch 63/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5490 - accuracy: 0.4374 - val_loss: 1.5157 - val_accuracy: 0.4932\n",
      "Epoch 64/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.5384 - accuracy: 0.4507 - val_loss: 1.5121 - val_accuracy: 0.4916\n",
      "Epoch 65/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5445 - accuracy: 0.4360 - val_loss: 1.5098 - val_accuracy: 0.4932\n",
      "Epoch 66/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5290 - accuracy: 0.4568 - val_loss: 1.5078 - val_accuracy: 0.4932\n",
      "Epoch 67/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5434 - accuracy: 0.4406 - val_loss: 1.5056 - val_accuracy: 0.4947\n",
      "Epoch 68/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5267 - accuracy: 0.4478 - val_loss: 1.5025 - val_accuracy: 0.4962\n",
      "Epoch 69/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5274 - accuracy: 0.4440 - val_loss: 1.5000 - val_accuracy: 0.4962\n",
      "Epoch 70/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5277 - accuracy: 0.4395 - val_loss: 1.4961 - val_accuracy: 0.4977\n",
      "Epoch 71/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5270 - accuracy: 0.4491 - val_loss: 1.4942 - val_accuracy: 0.4977\n",
      "Epoch 72/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.5040 - accuracy: 0.4662 - val_loss: 1.4919 - val_accuracy: 0.4992\n",
      "Epoch 73/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.5098 - accuracy: 0.4528 - val_loss: 1.4896 - val_accuracy: 0.4992\n",
      "Epoch 74/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4877 - accuracy: 0.4576 - val_loss: 1.4875 - val_accuracy: 0.4962\n",
      "Epoch 75/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.5112 - accuracy: 0.4523 - val_loss: 1.4851 - val_accuracy: 0.5008\n",
      "Epoch 76/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4951 - accuracy: 0.4611 - val_loss: 1.4817 - val_accuracy: 0.5008\n",
      "Epoch 77/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4881 - accuracy: 0.4624 - val_loss: 1.4791 - val_accuracy: 0.5053\n",
      "Epoch 78/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4804 - accuracy: 0.4691 - val_loss: 1.4774 - val_accuracy: 0.5053\n",
      "Epoch 79/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4882 - accuracy: 0.4598 - val_loss: 1.4763 - val_accuracy: 0.4962\n",
      "Epoch 80/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4677 - accuracy: 0.4733 - val_loss: 1.4746 - val_accuracy: 0.4947\n",
      "Epoch 81/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4667 - accuracy: 0.4744 - val_loss: 1.4723 - val_accuracy: 0.4962\n",
      "Epoch 82/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4801 - accuracy: 0.4675 - val_loss: 1.4700 - val_accuracy: 0.4947\n",
      "Epoch 83/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4728 - accuracy: 0.4784 - val_loss: 1.4677 - val_accuracy: 0.4977\n",
      "Epoch 84/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4545 - accuracy: 0.4827 - val_loss: 1.4651 - val_accuracy: 0.4977\n",
      "Epoch 85/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4581 - accuracy: 0.4781 - val_loss: 1.4638 - val_accuracy: 0.4977\n",
      "Epoch 86/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4570 - accuracy: 0.4765 - val_loss: 1.4630 - val_accuracy: 0.4962\n",
      "Epoch 87/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4483 - accuracy: 0.4867 - val_loss: 1.4617 - val_accuracy: 0.4977\n",
      "Epoch 88/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4561 - accuracy: 0.4891 - val_loss: 1.4611 - val_accuracy: 0.4947\n",
      "Epoch 89/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4422 - accuracy: 0.4797 - val_loss: 1.4594 - val_accuracy: 0.5008\n",
      "Epoch 90/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4420 - accuracy: 0.4904 - val_loss: 1.4578 - val_accuracy: 0.4977\n",
      "Epoch 91/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4339 - accuracy: 0.4888 - val_loss: 1.4556 - val_accuracy: 0.5008\n",
      "Epoch 92/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4253 - accuracy: 0.4872 - val_loss: 1.4536 - val_accuracy: 0.4992\n",
      "Epoch 93/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4262 - accuracy: 0.5003 - val_loss: 1.4534 - val_accuracy: 0.5038\n",
      "Epoch 94/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4182 - accuracy: 0.4957 - val_loss: 1.4527 - val_accuracy: 0.5038\n",
      "Epoch 95/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.4219 - accuracy: 0.4877 - val_loss: 1.4508 - val_accuracy: 0.5053\n",
      "Epoch 96/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4206 - accuracy: 0.4973 - val_loss: 1.4495 - val_accuracy: 0.5068\n",
      "Epoch 97/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4108 - accuracy: 0.4907 - val_loss: 1.4482 - val_accuracy: 0.5068\n",
      "Epoch 98/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4153 - accuracy: 0.4973 - val_loss: 1.4471 - val_accuracy: 0.5068\n",
      "Epoch 99/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4075 - accuracy: 0.5040 - val_loss: 1.4452 - val_accuracy: 0.5068\n",
      "Epoch 100/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4093 - accuracy: 0.4952 - val_loss: 1.4441 - val_accuracy: 0.5053\n",
      "Epoch 101/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4015 - accuracy: 0.5125 - val_loss: 1.4433 - val_accuracy: 0.5023\n",
      "Epoch 102/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.4107 - accuracy: 0.5008 - val_loss: 1.4420 - val_accuracy: 0.5053\n",
      "Epoch 103/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3972 - accuracy: 0.5085 - val_loss: 1.4405 - val_accuracy: 0.5084\n",
      "Epoch 104/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3954 - accuracy: 0.5107 - val_loss: 1.4395 - val_accuracy: 0.5068\n",
      "Epoch 105/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3937 - accuracy: 0.5088 - val_loss: 1.4381 - val_accuracy: 0.5053\n",
      "Epoch 106/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3895 - accuracy: 0.5059 - val_loss: 1.4375 - val_accuracy: 0.5053\n",
      "Epoch 107/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3880 - accuracy: 0.5157 - val_loss: 1.4349 - val_accuracy: 0.5068\n",
      "Epoch 108/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3939 - accuracy: 0.5059 - val_loss: 1.4339 - val_accuracy: 0.5068\n",
      "Epoch 109/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3844 - accuracy: 0.5032 - val_loss: 1.4330 - val_accuracy: 0.5114\n",
      "Epoch 110/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3801 - accuracy: 0.5045 - val_loss: 1.4313 - val_accuracy: 0.5099\n",
      "Epoch 111/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3821 - accuracy: 0.5125 - val_loss: 1.4316 - val_accuracy: 0.5099\n",
      "Epoch 112/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3631 - accuracy: 0.5203 - val_loss: 1.4305 - val_accuracy: 0.5114\n",
      "Epoch 113/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3708 - accuracy: 0.5112 - val_loss: 1.4300 - val_accuracy: 0.5114\n",
      "Epoch 114/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3737 - accuracy: 0.5133 - val_loss: 1.4276 - val_accuracy: 0.5114\n",
      "Epoch 115/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3610 - accuracy: 0.5195 - val_loss: 1.4272 - val_accuracy: 0.5145\n",
      "Epoch 116/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3464 - accuracy: 0.5187 - val_loss: 1.4264 - val_accuracy: 0.5129\n",
      "Epoch 117/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3587 - accuracy: 0.5181 - val_loss: 1.4254 - val_accuracy: 0.5175\n",
      "Epoch 118/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3395 - accuracy: 0.5299 - val_loss: 1.4249 - val_accuracy: 0.5175\n",
      "Epoch 119/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3533 - accuracy: 0.5280 - val_loss: 1.4243 - val_accuracy: 0.5175\n",
      "Epoch 120/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3312 - accuracy: 0.5272 - val_loss: 1.4215 - val_accuracy: 0.5175\n",
      "Epoch 121/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3404 - accuracy: 0.5221 - val_loss: 1.4212 - val_accuracy: 0.5190\n",
      "Epoch 122/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3499 - accuracy: 0.5291 - val_loss: 1.4211 - val_accuracy: 0.5160\n",
      "Epoch 123/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3346 - accuracy: 0.5341 - val_loss: 1.4219 - val_accuracy: 0.5160\n",
      "Epoch 124/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3347 - accuracy: 0.5179 - val_loss: 1.4213 - val_accuracy: 0.5175\n",
      "Epoch 125/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3265 - accuracy: 0.5402 - val_loss: 1.4198 - val_accuracy: 0.5175\n",
      "Epoch 126/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3299 - accuracy: 0.5349 - val_loss: 1.4195 - val_accuracy: 0.5175\n",
      "Epoch 127/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3078 - accuracy: 0.5410 - val_loss: 1.4182 - val_accuracy: 0.5160\n",
      "Epoch 128/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3267 - accuracy: 0.5328 - val_loss: 1.4172 - val_accuracy: 0.5175\n",
      "Epoch 129/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3210 - accuracy: 0.5413 - val_loss: 1.4157 - val_accuracy: 0.5160\n",
      "Epoch 130/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3121 - accuracy: 0.5413 - val_loss: 1.4152 - val_accuracy: 0.5175\n",
      "Epoch 131/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3058 - accuracy: 0.5434 - val_loss: 1.4157 - val_accuracy: 0.5160\n",
      "Epoch 132/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3020 - accuracy: 0.5418 - val_loss: 1.4145 - val_accuracy: 0.5160\n",
      "Epoch 133/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2971 - accuracy: 0.5506 - val_loss: 1.4141 - val_accuracy: 0.5114\n",
      "Epoch 134/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.3184 - accuracy: 0.5394 - val_loss: 1.4140 - val_accuracy: 0.5129\n",
      "Epoch 135/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3178 - accuracy: 0.5328 - val_loss: 1.4129 - val_accuracy: 0.5129\n",
      "Epoch 136/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2961 - accuracy: 0.5514 - val_loss: 1.4118 - val_accuracy: 0.5145\n",
      "Epoch 137/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2928 - accuracy: 0.5498 - val_loss: 1.4119 - val_accuracy: 0.5129\n",
      "Epoch 138/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2903 - accuracy: 0.5517 - val_loss: 1.4121 - val_accuracy: 0.5145\n",
      "Epoch 139/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2859 - accuracy: 0.5538 - val_loss: 1.4123 - val_accuracy: 0.5145\n",
      "Epoch 140/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2959 - accuracy: 0.5413 - val_loss: 1.4121 - val_accuracy: 0.5145\n",
      "Epoch 141/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2829 - accuracy: 0.5442 - val_loss: 1.4131 - val_accuracy: 0.5114\n",
      "Epoch 142/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2779 - accuracy: 0.5517 - val_loss: 1.4116 - val_accuracy: 0.5129\n",
      "Epoch 143/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2748 - accuracy: 0.5557 - val_loss: 1.4101 - val_accuracy: 0.5145\n",
      "Epoch 144/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.3016 - accuracy: 0.5448 - val_loss: 1.4091 - val_accuracy: 0.5099\n",
      "Epoch 145/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2684 - accuracy: 0.5552 - val_loss: 1.4078 - val_accuracy: 0.5084\n",
      "Epoch 146/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2795 - accuracy: 0.5488 - val_loss: 1.4085 - val_accuracy: 0.5099\n",
      "Epoch 147/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2719 - accuracy: 0.5618 - val_loss: 1.4093 - val_accuracy: 0.5160\n",
      "Epoch 148/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2590 - accuracy: 0.5594 - val_loss: 1.4066 - val_accuracy: 0.5129\n",
      "Epoch 149/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2680 - accuracy: 0.5594 - val_loss: 1.4072 - val_accuracy: 0.5099\n",
      "Epoch 150/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2481 - accuracy: 0.5648 - val_loss: 1.4063 - val_accuracy: 0.5114\n",
      "Epoch 151/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2652 - accuracy: 0.5530 - val_loss: 1.4068 - val_accuracy: 0.5129\n",
      "Epoch 152/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2670 - accuracy: 0.5570 - val_loss: 1.4065 - val_accuracy: 0.5145\n",
      "Epoch 153/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2492 - accuracy: 0.5621 - val_loss: 1.4059 - val_accuracy: 0.5160\n",
      "Epoch 154/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2495 - accuracy: 0.5669 - val_loss: 1.4046 - val_accuracy: 0.5129\n",
      "Epoch 155/600\n",
      "15/15 [==============================] - 0s 5ms/step - loss: 1.2292 - accuracy: 0.5778 - val_loss: 1.4046 - val_accuracy: 0.5129\n",
      "Epoch 156/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2394 - accuracy: 0.5789 - val_loss: 1.4028 - val_accuracy: 0.5160\n",
      "Epoch 157/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2489 - accuracy: 0.5605 - val_loss: 1.4034 - val_accuracy: 0.5145\n",
      "Epoch 158/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2490 - accuracy: 0.5728 - val_loss: 1.4024 - val_accuracy: 0.5129\n",
      "Epoch 159/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2375 - accuracy: 0.5677 - val_loss: 1.4015 - val_accuracy: 0.5129\n",
      "Epoch 160/600\n",
      "15/15 [==============================] - 0s 4ms/step - loss: 1.2293 - accuracy: 0.5802 - val_loss: 1.4013 - val_accuracy: 0.5129\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x220fefb5f08>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train, y=y_train, validation_data=(X_test, y_test), epochs=600, batch_size=64, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "   Electronic       0.38      0.45      0.41        75\n",
      " Experimental       0.11      0.14      0.12        29\n",
      "         Folk       0.64      0.65      0.64       118\n",
      "      Hip-Hop       0.60      0.62      0.61        87\n",
      " Instrumental       0.59      0.54      0.57        81\n",
      "International       0.42      0.49      0.45        65\n",
      "          Pop       0.44      0.28      0.34        87\n",
      "         Rock       0.60      0.59      0.60       115\n",
      "\n",
      "     accuracy                           0.51       657\n",
      "    macro avg       0.47      0.47      0.47       657\n",
      " weighted avg       0.52      0.51      0.51       657\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(converter.inverse_transform(np.argmax(y_test, axis=1)), converter.inverse_transform(np.argmax(pred, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[34  4  2 14  6  3  4  8]\n",
      " [ 2  4  8  2  5  4  0  4]\n",
      " [ 2  6 77  2  9 13  8  1]\n",
      " [19  3  1 54  0  5  2  3]\n",
      " [11  6  9  0 44  7  1  3]\n",
      " [ 8  2  5  8  1 32  4  5]\n",
      " [ 6  6 11  6  6  7 24 21]\n",
      " [ 8  7  8  4  3  6 11 68]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(converter.inverse_transform(np.argmax(y_test, axis=1)), converter.inverse_transform(np.argmax(pred, axis=1))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
